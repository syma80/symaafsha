{"ast":null,"code":"var _jsxFileName = \"F:\\\\mysite\\\\src\\\\ResearchBody.js\";\nimport React from \"react\";\nimport \"./research.css\";\nimport { Row, Col, Button } from \"react-bootstrap\";\nimport Paper from \"./image/flowchart-new.png\";\nimport SignPaper from \"./image/signpaper.jpg\";\nimport Violent from \"./image/violent.png\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function ResearchBody() {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"Researchbody\",\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"research-container\",\n      children: [/*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"research-text\",\n        children: /*#__PURE__*/_jsxDEV(\"b\", {\n          children: \"Research Highlights\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 13,\n          columnNumber: 42\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 13,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(Row, {\n        children: [/*#__PURE__*/_jsxDEV(Col, {\n          xs: 12,\n          md: 4,\n          lg: 4,\n          children: /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"card-research\",\n            children: [/*#__PURE__*/_jsxDEV(\"img\", {\n              src: Paper,\n              alt: \"paper\",\n              className: \"img-research1\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 19,\n              columnNumber: 13\n            }, this), /*#__PURE__*/_jsxDEV(\"hr\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 20,\n              columnNumber: 13\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"container\",\n              children: [/*#__PURE__*/_jsxDEV(Button, {\n                className: \"button\",\n                children: /*#__PURE__*/_jsxDEV(\"a\", {\n                  href: \" https://ieeexplore.ieee.org/abstract/document/9775816\",\n                  target: \"_blank\",\n                  children: \"IEEEXPLORE\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 26,\n                  columnNumber: 2\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 25,\n                columnNumber: 2\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 27,\n                columnNumber: 2\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  fontSize: 15,\n                  textAlign: \"justify\",\n                  fontFamily: \"Georgia, serif\",\n                  margin: 5\n                },\n                children: /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: \"Machine Learning Models for Content Classification in Film Censorship and Rating.\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 30,\n                  columnNumber: 93\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 30,\n                columnNumber: 5\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  color: \"gray\",\n                  margin: 5,\n                  fontSize: 14\n                },\n                children: \"Automated Film Censorship and Rating (AFCR) has recently turned out to be a major research area of Machine Learning (ML). The production and streaming services of films including movies, tv-series, animations and other audio-visual contents have been widely expanded leading to their manual censorship and rating to be a more exhausting task. Development of ML based methods has thus been emerging to designing an AFCR system. However, the initial ad-hoc efforts of developing the AFCR system demand a \\u201Ccomplete\\u201D conceptual model of the system with its potential classes and their criteria. This paper primarily attempts to determine both the general and contextual classes of the content, and their criteria for an AFCR system. Besides, the state-of-the-art AFCR systems have been systematically reviewed to identify their underlying ML models, advantages and limitations. With a comparative analysis of the exiting ML models, we have demonstrated the effectiveness of sequential and multimodal analysis in the development of an efficient AFCR system.\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 32,\n                columnNumber: 5\n              }, this), \"  \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 45,\n                columnNumber: 198\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 46,\n                columnNumber: 1\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 46,\n                columnNumber: 7\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 46,\n                columnNumber: 13\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 46,\n                columnNumber: 19\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  fontSize: 12,\n                  textAlign: \"justify\",\n                  fontFamily: \"Georgia, serif\",\n                  margin: 5\n                },\n                children: \"2022 International Conference on Innovations in Science, Engineering and Technology.\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 47,\n                columnNumber: 1\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 22,\n              columnNumber: 3\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 18,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 16,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(Col, {\n          xs: 12,\n          md: 4,\n          lg: 4,\n          children: /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"card1-research\",\n            children: [/*#__PURE__*/_jsxDEV(\"img\", {\n              src: Violent,\n              alt: \"violent\",\n              className: \"img-research2\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 61,\n              columnNumber: 13\n            }, this), /*#__PURE__*/_jsxDEV(\"hr\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 62,\n              columnNumber: 13\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"container\",\n              children: [/*#__PURE__*/_jsxDEV(Button, {\n                className: \"button\",\n                children: /*#__PURE__*/_jsxDEV(\"a\", {\n                  href: \" https://ieeexplore.ieee.org/abstract/document/9775874\",\n                  target: \"_blank\",\n                  children: \"IEEEXPLORE\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 68,\n                  columnNumber: 2\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 67,\n                columnNumber: 2\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 69,\n                columnNumber: 2\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  fontSize: 15,\n                  textAlign: \"justify\",\n                  fontFamily: \"Georgia, serif\",\n                  margin: 5\n                },\n                children: /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: \"Developing BrutNet: A New Deep CNN Model with GRU for Realtime Violence Detection.\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 72,\n                  columnNumber: 93\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 72,\n                columnNumber: 5\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  color: \"gray\",\n                  margin: 5,\n                  fontSize: 14\n                },\n                children: \"Computer vision with deep learning has recently emerged for Automatic Violence Detection and Classification (AVDC) with enormous potential. This paper reports an early development of a new Deep Convolutional Neural Network (DCNN) model that we call BrutNet. Building on the Gated Recurrent Unit (GRU), the BrutNet is designed to operate on the patterns within multiple frames of a video or video clips of shape 160 \\xD7 90 with a duration of at least 3 seconds. For obtaining the image-feature set and the pattern of each frame, convolutional layers were considered for each frame of the time distributed layer. The model thus encodes the data from 4D to 2D to obtain a 512-features set for each frame. The temporal nature of these frames is then extracted by the GRU layer as a 1D vector, which is processed by several dense layers. A binary classification is thereby performed denoting the content as violent and non-violent. Dropout layers with a dropping rate of 0.25 were added to avoid overfitting the model. Besides, ReLu-activation and sigmoid-activation functions were defined in the hidden and output layers, respectively. Being trained with a recent high-resolution AVDC video dataset and appropriate hyper-parameters on the NVIDIA Tesla K80 GPU of Google Colab, the initial testing and validation of the model has recorded a test accuracy of 90.00% outperforming the earlier LSTM based ResNet50 model.\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 74,\n                columnNumber: 5\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 95,\n                columnNumber: 32\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  fontSize: 12,\n                  textAlign: \"justify\",\n                  fontFamily: \"Georgia, serif\",\n                  margin: 5\n                },\n                children: \"2022 International Conference on Innovations in Science, Engineering and Technology.\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 96,\n                columnNumber: 1\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 64,\n              columnNumber: 3\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 60,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 58,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(Col, {\n          xs: 12,\n          md: 4,\n          lg: 4,\n          children: /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"card2-research\",\n            children: [/*#__PURE__*/_jsxDEV(\"img\", {\n              src: SignPaper,\n              alt: \"signpaper\",\n              className: \"img-research\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 109,\n              columnNumber: 20\n            }, this), /*#__PURE__*/_jsxDEV(\"hr\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 110,\n              columnNumber: 20\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"container\",\n              children: [/*#__PURE__*/_jsxDEV(Button, {\n                className: \"button\",\n                children: /*#__PURE__*/_jsxDEV(\"a\", {\n                  href: \"https://ieeexplore.ieee.org/document/9667804\",\n                  target: \"_blank\",\n                  children: \"IEEEXPLORE\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 116,\n                  columnNumber: 9\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 115,\n                columnNumber: 9\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 117,\n                columnNumber: 9\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  fontSize: 15,\n                  textAlign: \"justify\",\n                  fontFamily: \"Georgia, serif\",\n                  margin: 5\n                },\n                children: /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: \"Improving Automatic Sign Language Translation with Image Binarisation and Deep Learning.\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 120,\n                  columnNumber: 100\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 120,\n                columnNumber: 12\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  color: \"gray\",\n                  margin: 5,\n                  fontSize: 14\n                },\n                children: \" Sign Language Translation (SLT) has been widely investigated to provide a futuristic solution to tackle human speech and hearing disability. Recent deep learning-based SLT models have redefined computer vision-based detection and classification to automatically translate the hand-gestured based sign language (SL) into natural language (NL) with higher accuracy. Unlike the existing models that directly learn from the natural image-sets, in this paper, we propose a 2D Convolutional Neural Network (CNN) model with customised hyper-parameters to be trained with binary SL image-sets. We thus introduce a binarisation step to preprocess the images of size 28 \\xD7 28 to feed the model. Preliminary results of our model trained with binarised image-set demonstrate its potential with an impressive classification accuracy of 99.99% on the NVIDIA Tesla K80 GPU environment (Google Colab) for an automatic SLT system.\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 12\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 982\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 987\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 993\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 999\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 1005\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 121,\n                columnNumber: 1011\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                style: {\n                  fontSize: 12,\n                  textAlign: \"justify\",\n                  fontFamily: \"Georgia, serif\",\n                  margin: 5\n                },\n                children: \"2021 5th International Conference on Electrical Engineering and Information Communication Technology (ICEEICT).\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 122,\n                columnNumber: 8\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 112,\n              columnNumber: 10\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 108,\n            columnNumber: 20\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 106,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 14,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 11,\n    columnNumber: 9\n  }, this);\n}\n_c = ResearchBody;\nvar _c;\n$RefreshReg$(_c, \"ResearchBody\");","map":{"version":3,"names":["React","Row","Col","Button","Paper","SignPaper","Violent","jsxDEV","_jsxDEV","ResearchBody","className","children","fileName","_jsxFileName","lineNumber","columnNumber","xs","md","lg","src","alt","href","target","style","fontSize","textAlign","fontFamily","margin","color","_c","$RefreshReg$"],"sources":["F:/mysite/src/ResearchBody.js"],"sourcesContent":["import React from \"react\";\r\nimport \"./research.css\";\r\nimport {Row, Col, Button} from \"react-bootstrap\"\r\nimport Paper from \"./image/flowchart-new.png\";\r\nimport SignPaper from \"./image/signpaper.jpg\"\r\nimport Violent from \"./image/violent.png\"\r\n\r\n\r\nexport default function ResearchBody(){\r\n    return(\r\n        <div className=\"Researchbody\">\r\n            <div className=\"research-container\">\r\n            <p className=\"research-text\"><b>Research Highlights</b></p>\r\n                <Row>\r\n\r\n                    <Col xs={12} md={4} lg={4}>\r\n              \r\n            <div className=\"card-research\">\r\n            <img src= {Paper} alt=\"paper\" className=\"img-research1\" />\r\n            <hr/>\r\n            {/* <span class=\"tag tag-purple\">Published</span> */}\r\n  <div className=\"container\">\r\n  {/* <Button className=\"button\">\r\n <a href=\"https://www.researchgate.net/profile/Mahmudul-Haque-4/publication/360812725_Machine_Learning_Models_for_Content_Classification_in_Film_Censorship_and_Rating/links/629219a58d19206823e2cf70/Machine-Learning-Models-for-Content-Classification-in-Film-Censorship-and-Rating.pdf\" target=\"_blank\">Published</a></Button> */}\r\n <Button className=\"button\" >\r\n <a href=\" https://ieeexplore.ieee.org/abstract/document/9775816\" target=\"_blank\">IEEEXPLORE</a></Button>\r\n <br/>\r\n \r\n  \r\n    <p style={{fontSize:15, textAlign: \"justify\" , fontFamily:\"Georgia, serif\", margin: 5}}><b>Machine Learning Models for Content\r\nClassification in Film Censorship and Rating.</b></p> \r\n    <p style={{color: \"gray\", margin: 5, fontSize: 14}}>Automated Film Censorship and Rating (AFCR) has\r\nrecently turned out to be a major research area of Machine\r\nLearning (ML). The production and streaming services of films\r\nincluding movies, tv-series, animations and other audio-visual\r\ncontents have been widely expanded leading to their manual\r\ncensorship and rating to be a more exhausting task. Development\r\nof ML based methods has thus been emerging to designing an\r\nAFCR system. However, the initial ad-hoc efforts of developing\r\nthe AFCR system demand a “complete” conceptual model of the\r\nsystem with its potential classes and their criteria. This paper\r\nprimarily attempts to determine both the general and contextual\r\nclasses of the content, and their criteria for an AFCR system. Besides, the state-of-the-art AFCR systems have been systematically\r\nreviewed to identify their underlying ML models, advantages and\r\nlimitations. With a comparative analysis of the exiting ML models, we have demonstrated the effectiveness of sequential and multimodal analysis in the development of an efficient AFCR system.</p>  <br/>\r\n<br/> <br/> <br/> <br/>\r\n<p  style={{ fontSize: 12, textAlign: \"justify\" , fontFamily:\"Georgia, serif\", margin: 5}}>2022 International Conference on Innovations in Science, Engineering and\r\nTechnology.</p>\r\n  </div>\r\n \r\n\r\n  </div>\r\n\r\n                    </Col>\r\n\r\n\r\n\r\n                    <Col xs={12} md={4} lg={4}>\r\n                   \r\n            <div className=\"card1-research\" >\r\n            <img src= {Violent} alt=\"violent\" className=\"img-research2\" />\r\n            <hr/>\r\n            {/* <span class=\"tag tag-purple\">Published</span> */}\r\n  <div className=\"container\">\r\n  {/* <Button className=\"button\">\r\n <a href=\"https://www.researchgate.net/profile/Mahmudul-Haque-4/publication/360812725_Machine_Learning_Models_for_Content_Classification_in_Film_Censorship_and_Rating/links/629219a58d19206823e2cf70/Machine-Learning-Models-for-Content-Classification-in-Film-Censorship-and-Rating.pdf\" target=\"_blank\">Published</a></Button> */}\r\n <Button className=\"button\">\r\n <a href=\" https://ieeexplore.ieee.org/abstract/document/9775874\" target=\"_blank\">IEEEXPLORE</a></Button>\r\n <br/>\r\n \r\n  \r\n    <p style={{fontSize:15, textAlign: \"justify\" , fontFamily:\"Georgia, serif\", margin: 5}}><b>Developing BrutNet: A New Deep CNN Model with GRU for\r\nRealtime Violence Detection.</b></p> \r\n    <p style={{color: \"gray\", margin: 5, fontSize: 14}}>Computer vision with deep learning has recently\r\nemerged for Automatic Violence Detection and Classification\r\n(AVDC) with enormous potential. This paper reports an early development of a new Deep Convolutional Neural Network (DCNN)\r\nmodel that we call BrutNet. Building on the Gated Recurrent Unit\r\n(GRU), the BrutNet is designed to operate on the patterns within\r\nmultiple frames of a video or video clips of shape 160 × 90 with\r\na duration of at least 3 seconds. For obtaining the image-feature\r\nset and the pattern of each frame, convolutional layers were\r\nconsidered for each frame of the time distributed layer. The model\r\nthus encodes the data from 4D to 2D to obtain a 512-features\r\nset for each frame. The temporal nature of these frames is then\r\nextracted by the GRU layer as a 1D vector, which is processed by\r\nseveral dense layers. A binary classification is thereby performed\r\ndenoting the content as violent and non-violent. Dropout layers\r\nwith a dropping rate of 0.25 were added to avoid overfitting the\r\nmodel. Besides, ReLu-activation and sigmoid-activation functions\r\nwere defined in the hidden and output layers, respectively. Being\r\ntrained with a recent high-resolution AVDC video dataset and\r\nappropriate hyper-parameters on the NVIDIA Tesla K80 GPU of\r\nGoogle Colab, the initial testing and validation of the model has\r\nrecorded a test accuracy of 90.00% outperforming the earlier\r\nLSTM based ResNet50 model.</p> <br/> \r\n<p  style={{ fontSize: 12, textAlign: \"justify\" , fontFamily:\"Georgia, serif\", margin: 5}}>2022 International Conference on Innovations in Science, Engineering and\r\nTechnology.</p>\r\n  </div>\r\n \r\n\r\n  </div>\r\n\r\n                    </Col>\r\n\r\n\r\n                    <Col xs={12} md={4} lg={4}>\r\n                   \r\n                   <div className=\"card2-research\" >\r\n                   <img src= {SignPaper} alt=\"signpaper\" className=\"img-research\" />\r\n                   <hr/>\r\n                   {/* <span class=\"tag tag-purple\">Published</span> */}\r\n         <div className=\"container\">\r\n         {/* <Button className=\"button\">\r\n        <a href=\"https://www.researchgate.net/profile/Mahmudul-Haque-4/publication/360812725_Machine_Learning_Models_for_Content_Classification_in_Film_Censorship_and_Rating/links/629219a58d19206823e2cf70/Machine-Learning-Models-for-Content-Classification-in-Film-Censorship-and-Rating.pdf\" target=\"_blank\">Published</a></Button> */}\r\n        <Button className=\"button\">\r\n        <a href=\"https://ieeexplore.ieee.org/document/9667804\"  target=\"_blank\">IEEEXPLORE</a></Button>\r\n        <br/>\r\n        \r\n         \r\n           <p style={{fontSize:15, textAlign: \"justify\" , fontFamily:\"Georgia, serif\", margin: 5}}><b>Improving Automatic Sign Language Translation with Image Binarisation and Deep Learning.</b></p> \r\n           <p style={{color: \"gray\", margin: 5, fontSize: 14}}> Sign Language Translation (SLT) has been widely investigated to provide a futuristic solution to tackle human speech and hearing disability. Recent deep learning-based SLT models have redefined computer vision-based detection and classification to automatically translate the hand-gestured based sign language (SL) into natural language (NL) with higher accuracy. Unlike the existing models that directly learn from the natural image-sets, in this paper, we propose a 2D Convolutional Neural Network (CNN) model with customised hyper-parameters to be trained with binary SL image-sets. We thus introduce a binarisation step to preprocess the images of size 28 × 28 to feed the model. Preliminary results of our model trained with binarised image-set demonstrate its potential with an impressive classification accuracy of 99.99% on the NVIDIA Tesla K80 GPU environment (Google Colab) for an automatic SLT system.</p> <br/><br/> <br/> <br/> <br/> <br/>\r\n       <p  style={{ fontSize: 12, textAlign: \"justify\" , fontFamily:\"Georgia, serif\", margin: 5}}>2021 5th International Conference on Electrical Engineering and\r\nInformation Communication Technology (ICEEICT).</p>\r\n         </div>\r\n        \r\n       \r\n         </div>\r\n       \r\n                           </Col>\r\n         \r\n                </Row>\r\n           \r\n\r\n            \r\n            </div>\r\n\r\n\r\n            \r\n         \r\n\r\n        </div>\r\n    )\r\n}"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAO,gBAAgB;AACvB,SAAQC,GAAG,EAAEC,GAAG,EAAEC,MAAM,QAAO,iBAAiB;AAChD,OAAOC,KAAK,MAAM,2BAA2B;AAC7C,OAAOC,SAAS,MAAM,uBAAuB;AAC7C,OAAOC,OAAO,MAAM,qBAAqB;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAGzC,eAAe,SAASC,YAAYA,CAAA,EAAE;EAClC,oBACID,OAAA;IAAKE,SAAS,EAAC,cAAc;IAAAC,QAAA,eACzBH,OAAA;MAAKE,SAAS,EAAC,oBAAoB;MAAAC,QAAA,gBACnCH,OAAA;QAAGE,SAAS,EAAC,eAAe;QAAAC,QAAA,eAACH,OAAA;UAAAG,QAAA,EAAG;QAAmB;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eACvDP,OAAA,CAACP,GAAG;QAAAU,QAAA,gBAEAH,OAAA,CAACN,GAAG;UAACc,EAAE,EAAE,EAAG;UAACC,EAAE,EAAE,CAAE;UAACC,EAAE,EAAE,CAAE;UAAAP,QAAA,eAElCH,OAAA;YAAKE,SAAS,EAAC,eAAe;YAAAC,QAAA,gBAC9BH,OAAA;cAAKW,GAAG,EAAGf,KAAM;cAACgB,GAAG,EAAC,OAAO;cAACV,SAAS,EAAC;YAAe;cAAAE,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAE,CAAC,eAC1DP,OAAA;cAAAI,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAI,CAAC,eAEfP,OAAA;cAAKE,SAAS,EAAC,WAAW;cAAAC,QAAA,gBAG3BH,OAAA,CAACL,MAAM;gBAACO,SAAS,EAAC,QAAQ;gBAAAC,QAAA,eAC1BH,OAAA;kBAAGa,IAAI,EAAC,wDAAwD;kBAACC,MAAM,EAAC,QAAQ;kBAAAX,QAAA,EAAC;gBAAU;kBAAAC,QAAA,EAAAC,YAAA;kBAAAC,UAAA;kBAAAC,YAAA;gBAAA,OAAG;cAAC;gBAAAH,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAQ,CAAC,eACxGP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eAGFP,OAAA;gBAAGe,KAAK,EAAE;kBAACC,QAAQ,EAAC,EAAE;kBAAEC,SAAS,EAAE,SAAS;kBAAGC,UAAU,EAAC,gBAAgB;kBAAEC,MAAM,EAAE;gBAAC,CAAE;gBAAAhB,QAAA,eAACH,OAAA;kBAAAG,QAAA,EAAG;gBAClD;kBAAAC,QAAA,EAAAC,YAAA;kBAAAC,UAAA;kBAAAC,YAAA;gBAAA,OAAG;cAAC;gBAAAH,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC,eACjDP,OAAA;gBAAGe,KAAK,EAAE;kBAACK,KAAK,EAAE,MAAM;kBAAED,MAAM,EAAE,CAAC;kBAAEH,QAAQ,EAAE;gBAAE,CAAE;gBAAAb,QAAA,EAAC;cAauI;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC,MAAE,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eAC1MP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eACvBP,OAAA;gBAAIe,KAAK,EAAE;kBAAEC,QAAQ,EAAE,EAAE;kBAAEC,SAAS,EAAE,SAAS;kBAAGC,UAAU,EAAC,gBAAgB;kBAAEC,MAAM,EAAE;gBAAC,CAAE;gBAAAhB,QAAA,EAAC;cAChF;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC;YAAA;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACR,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAGD;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAEiB,CAAC,eAINP,OAAA,CAACN,GAAG;UAACc,EAAE,EAAE,EAAG;UAACC,EAAE,EAAE,CAAE;UAACC,EAAE,EAAE,CAAE;UAAAP,QAAA,eAElCH,OAAA;YAAKE,SAAS,EAAC,gBAAgB;YAAAC,QAAA,gBAC/BH,OAAA;cAAKW,GAAG,EAAGb,OAAQ;cAACc,GAAG,EAAC,SAAS;cAACV,SAAS,EAAC;YAAe;cAAAE,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAE,CAAC,eAC9DP,OAAA;cAAAI,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAI,CAAC,eAEfP,OAAA;cAAKE,SAAS,EAAC,WAAW;cAAAC,QAAA,gBAG3BH,OAAA,CAACL,MAAM;gBAACO,SAAS,EAAC,QAAQ;gBAAAC,QAAA,eAC1BH,OAAA;kBAAGa,IAAI,EAAC,wDAAwD;kBAACC,MAAM,EAAC,QAAQ;kBAAAX,QAAA,EAAC;gBAAU;kBAAAC,QAAA,EAAAC,YAAA;kBAAAC,UAAA;kBAAAC,YAAA;gBAAA,OAAG;cAAC;gBAAAH,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAQ,CAAC,eACxGP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eAGFP,OAAA;gBAAGe,KAAK,EAAE;kBAACC,QAAQ,EAAC,EAAE;kBAAEC,SAAS,EAAE,SAAS;kBAAGC,UAAU,EAAC,gBAAgB;kBAAEC,MAAM,EAAE;gBAAC,CAAE;gBAAAhB,QAAA,eAACH,OAAA;kBAAAG,QAAA,EAAG;gBACnE;kBAAAC,QAAA,EAAAC,YAAA;kBAAAC,UAAA;kBAAAC,YAAA;gBAAA,OAAG;cAAC;gBAAAH,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC,eAChCP,OAAA;gBAAGe,KAAK,EAAE;kBAACK,KAAK,EAAE,MAAM;kBAAED,MAAM,EAAE,CAAC;kBAAEH,QAAQ,EAAE;gBAAE,CAAE;gBAAAb,QAAA,EAAC;cAqB9B;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eACpCP,OAAA;gBAAIe,KAAK,EAAE;kBAAEC,QAAQ,EAAE,EAAE;kBAAEC,SAAS,EAAE,SAAS;kBAAGC,UAAU,EAAC,gBAAgB;kBAAEC,MAAM,EAAE;gBAAC,CAAE;gBAAAhB,QAAA,EAAC;cAChF;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC;YAAA;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACR,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAGD;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAEiB,CAAC,eAGNP,OAAA,CAACN,GAAG;UAACc,EAAE,EAAE,EAAG;UAACC,EAAE,EAAE,CAAE;UAACC,EAAE,EAAE,CAAE;UAAAP,QAAA,eAE3BH,OAAA;YAAKE,SAAS,EAAC,gBAAgB;YAAAC,QAAA,gBAC/BH,OAAA;cAAKW,GAAG,EAAGd,SAAU;cAACe,GAAG,EAAC,WAAW;cAACV,SAAS,EAAC;YAAc;cAAAE,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAE,CAAC,eACjEP,OAAA;cAAAI,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAI,CAAC,eAEfP,OAAA;cAAKE,SAAS,EAAC,WAAW;cAAAC,QAAA,gBAG3BH,OAAA,CAACL,MAAM;gBAACO,SAAS,EAAC,QAAQ;gBAAAC,QAAA,eAC1BH,OAAA;kBAAGa,IAAI,EAAC,8CAA8C;kBAAEC,MAAM,EAAC,QAAQ;kBAAAX,QAAA,EAAC;gBAAU;kBAAAC,QAAA,EAAAC,YAAA;kBAAAC,UAAA;kBAAAC,YAAA;gBAAA,OAAG;cAAC;gBAAAH,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAQ,CAAC,eAC/FP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eAGFP,OAAA;gBAAGe,KAAK,EAAE;kBAACC,QAAQ,EAAC,EAAE;kBAAEC,SAAS,EAAE,SAAS;kBAAGC,UAAU,EAAC,gBAAgB;kBAAEC,MAAM,EAAE;gBAAC,CAAE;gBAAAhB,QAAA,eAACH,OAAA;kBAAAG,QAAA,EAAG;gBAAwF;kBAAAC,QAAA,EAAAC,YAAA;kBAAAC,UAAA;kBAAAC,YAAA;gBAAA,OAAG;cAAC;gBAAAH,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC,eAC3LP,OAAA;gBAAGe,KAAK,EAAE;kBAACK,KAAK,EAAE,MAAM;kBAAED,MAAM,EAAE,CAAC;kBAAEH,QAAQ,EAAE;gBAAE,CAAE;gBAAAb,QAAA,EAAC;cAAi5B;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,KAAC,eAAAP,OAAA;gBAAAI,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eACh/BP,OAAA;gBAAIe,KAAK,EAAE;kBAAEC,QAAQ,EAAE,EAAE;kBAAEC,SAAS,EAAE,SAAS;kBAAGC,UAAU,EAAC,gBAAgB;kBAAEC,MAAM,EAAE;gBAAC,CAAE;gBAAAhB,QAAA,EAAC;cACnD;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAG,CAAC;YAAA;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACrC,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAGD;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAEiB,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAEZ,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAIL;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAML,CAAC;AAEd;AAACc,EAAA,GAtIuBpB,YAAY;AAAA,IAAAoB,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}